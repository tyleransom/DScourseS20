{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to [JuMP](https://github.com/JuliaOpt/JuMP.jl/blob/master/README.md)\n",
    "\n",
    "February 27, 2020\n",
    "\n",
    "*Uses JuMP version 0.21*\n",
    "\n",
    "### What is JuMP?\n",
    "JuMP stands for **Ju**lia for **M**athematical Programming. It is a \"domain-specific modeling language for mathematical optimization embedded in Julia.\"\n",
    "\n",
    "What does \"domain-specific\" mean? It means that some algorithms are useful in some knowledge domains (e.g. supply chain management) that may not be useful in other knowledge domains (e.g. estimating statistical model parameters).\n",
    "\n",
    "What is great about JuMP is that it allows the user to change algorithms with little or no change to the modeling code. This means that someone without domain-specific knowledge can easily utilize JuMP to accomplish a task that would otherwise be impossible.\n",
    "\n",
    "### What goes into JuMP?\n",
    "To use JuMP, a user must specify the following components:\n",
    "\n",
    "- An objective function (you gotta solve something!)\n",
    "- Variables\n",
    "- Constraints\n",
    "\n",
    "JuMP does the rest! (I'll show you examples shortly of how you can do this.)\n",
    "\n",
    "### What kinds of problems can JuMP handle?\n",
    "JuMP provides the ability to solve the following types of objective functions:\n",
    "\n",
    "- Linear\n",
    "- Convex Quadratic\n",
    "- Nonlinear (convex and nonconvex)\n",
    "\n",
    "It also provides the ability to use constraints of the following types:\n",
    "\n",
    "- Linear\n",
    "- Convex Quadratic\n",
    "- Second-order Conic\n",
    "- Semidefinite\n",
    "- Nonlinear (convex and nonconvex)\n",
    "\n",
    "Finally, it provides support for any of the following types of variables:\n",
    "\n",
    "- Continuous\n",
    "- Integer-valued\n",
    "- Semicontinuous\n",
    "- Semi-integer\n",
    "\n",
    "### What examples will we go through today?\n",
    "Today I'll go through four examples:\n",
    "\n",
    "1. Solve a very simple constrained system of equations (adapted from JuMP's Github repository [here](https://github.com/JuliaOpt/JuMP.jl/blob/master/examples/basic.jl))\n",
    "2. Solve a Sudoku puzzle (adapted from JuMP's Github repository [here](https://github.com/JuliaOpt/JuMP.jl/blob/master/examples/sudoku.jl))\n",
    "3. Solve a professional sports team's salary budget problem\n",
    "4. Estimate the parameters of a linear regression model\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. A simple constrained system of equations\n",
    "Suppose you want to solve the following (constrained) system of equations:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\max\\,\\, 5x + 3y\n",
    "\\end{equation*}\n",
    "\n",
    "subject to the following constraints:\n",
    "\n",
    "\\begin{align}\n",
    "x + 5y & \\leq 3 \\\\\n",
    "x & \\geq 0 \\\\\n",
    "y & \\geq 0 \\\\\n",
    "x & \\leq 2 \\\\\n",
    "y & \\leq 30 \\\\\n",
    "\\end{align}\n",
    "\n",
    "In economics, this problem may represent a utility maximization problem, where utility is linear in $x$ and $y$, the individul has an income of 3, and the price of good $x$ is 1, with the price of good $y$ equal to 5. (And there are supply constraints on $x$ and $y$ governed by the market in general.)\n",
    "\n",
    "If we wanted to, we could solve this using a Lagrangian (although in this case with linear utility, we know we will have a corner solution, so no need to bother with calculus). \n",
    "\n",
    "But we want the computer to do this, so let's see how it's done.\n",
    "\n",
    "### Specifying the model components\n",
    "As explained above, JuMP needs an objective function, variables, and constraints. Additionally, we need to tell JuMP which optimization algorithm to use.\n",
    "\n",
    "#### Optimizer\n",
    "The first step is to declare a model and attach an optimizer. We are going to use the GLPK optimizer:\n",
    "```julia\n",
    "model = Model(GLPK.Optimizer)\n",
    "```\n",
    "\n",
    "#### Variables\n",
    "Next, we need to tell it what the variables are, and any constraints on those variables:\n",
    "```julia\n",
    "@variable(model, 0 <= x <= 2)\n",
    "@variable(model, 0 <= y <= 30)\n",
    "```\n",
    "\n",
    "#### Objective function\n",
    "Next, we tell it the objective function (and whether we want to maximize or minimize):\n",
    "```julia\n",
    "@objective(model, Max, 5x + 3y)\n",
    "```\n",
    "\n",
    "#### Constraints\n",
    "Finally, we give it the constraints. Note that the single constraints on each variable were incorporated when we declared the variables themselves, but we have one additional constraint that is a function of both variables. We could also impose a constraint that the optimal values of $x$ and $y$ be integers (if these represented indivisible objects, for example).\n",
    "```julia\n",
    "@constraint(model, 1x + 5y <= 3)\n",
    "```\n",
    "\n",
    "### Optimizing the model\n",
    "Once we have all of the components declared, we can optimize the model:\n",
    "```julia\n",
    "JuMP.optimize!(model)\n",
    "```\n",
    "\n",
    "We can then look at the output of the optimization as follows:\n",
    "```julia\n",
    "obj_value = JuMP.objective_value(model)\n",
    "x_value   = JuMP.value(x)\n",
    "y_value   = JuMP.value(y)\n",
    "```\n",
    "We'll put all of the code together below so it can be run on your machine.\n",
    "\n",
    "Following Julia protocol, we will also wrap everything in a function and then call that function.\n",
    "\n",
    "### All of the code together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max 5 x + 3 y\n",
      "Subject to\n",
      " x + 5 y <= 3.0\n",
      " x >= 0.0\n",
      " y >= 0.0\n",
      " x <= 2.0\n",
      " y <= 30.0\n",
      "Objective value: 10.6\n",
      "x = 2.0\n",
      "y = 0.2\n"
     ]
    }
   ],
   "source": [
    "using JuMP, GLPK\n",
    "\n",
    "\n",
    "# wrap all of our code inside a function (for better performance)\n",
    "function example_basic()\n",
    "    \n",
    "    # define model and optimizer\n",
    "    model = Model(GLPK.Optimizer)\n",
    "    \n",
    "    # define variables\n",
    "    @variable(model, 0 <= x <= 2)\n",
    "    @variable(model, 0 <= y <= 30)\n",
    "\n",
    "    # define objective function\n",
    "    @objective(model, Max, 5x + 3y)\n",
    "    \n",
    "    # add additional constraints\n",
    "    @constraint(model, 1x + 5y <= 3.0)\n",
    "\n",
    "    # display the model\n",
    "    print(model)\n",
    "    \n",
    "    # optimize the model\n",
    "    JuMP.optimize!(model)\n",
    "\n",
    "    # return and print objective function and optimal values of variables\n",
    "    obj_value = JuMP.objective_value(model)\n",
    "    x_value = JuMP.value(x)\n",
    "    y_value = JuMP.value(y)\n",
    "    println(\"Objective value: \", obj_value)\n",
    "    println(\"x = \", x_value)\n",
    "    println(\"y = \", y_value)\n",
    "end\n",
    "\n",
    "\n",
    "# call the function defined above\n",
    "example_basic()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our optimal values are:\n",
    "\n",
    "\\begin{align}\n",
    "x^* & = 2 \\\\\n",
    "y^* & = 0.2 \\\\\n",
    "\\text{Objective} & = 10.6\n",
    "\\end{align}\n",
    "\n",
    "As I mentioned before we did any programming, this problem would yield a corner solution (where, for one of the goods, the optimal value hits one of the constraints). In this case, it was $x^* = 2$.\n",
    "\n",
    "#### Other types of constraints\n",
    "As I mentioned above, we can also add other constraints, for example, that the optimal values be integers (e.g. if $x$ and $y$ are indivisible). In this case, we would add `@constraint(model, x in MOI.Integer())` and similar for $y$.\n",
    "\n",
    "We could also put a constraint on the objective function itself (e.g. that the objective value be no larger than 10). To do this we would add the following:\n",
    "```julia\n",
    "@expression(model, objval, 5x + 3y)\n",
    "@constraint(model, objval <= 10)\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Solving a Sudoku puzzle\n",
    "Now that we are more comfortable with JuMP, we can solve a Sudoku puzzle. All we need to do is appropriately tell JuMP how to understand the puzzle board.\n",
    "\n",
    "### Sudoku objective\n",
    "In this case, the objective function is to fill in the puzzle board given a starting grid that has some numbers filled in. We won't have a formal objective function for this; we will just give JuMP a starting grid and tell it to satisfy all of the constraints, where one of the constraints is that the board gets filled. (A blank board has an infinite number of solutions, but a partially completed board should have just one unique solution.)\n",
    "\n",
    "### Sudoku variables\n",
    "We will communicate the state of the puzzle board with an array of variables. The variables will be put in a 3-dimensional array, where the first two dimensions tell the \"latitude\" and \"longitude\" of the cell on the puzzle board, and the third dimension keeps track of which of the numbers 1-9 will fill that cell.\n",
    "\n",
    "Mathematically, we have\n",
    "```julia\n",
    "x[i, j, k]\n",
    "```\n",
    "which, if equal to 1, indicates that cell $(i,j)$ should contain the number $k$. The indices $(i,j,k)$ each must take on integer values from 1 to 9, since the puzzle board has 81 squares. So our `x` array is a 9 x 9 x 9 cube.\n",
    "\n",
    "### Sudoku constraints\n",
    "The constraints of Sudoku are as follows:\n",
    "\n",
    "1. Each cell can only contain one number (duh, but we have to explain this to the computer!)\n",
    "2. Each row contains each number exactly once\n",
    "3. Each column contains each number exactly once\n",
    "4. Each 3x3 subgrid contains each number exactly once\n",
    "\n",
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution:\n",
      "[-----------------------]\n",
      "[ 3 1 7 | 9 5 8 | 2 6 4 ]\n",
      "[ 4 6 9 | 3 2 7 | 8 1 5 ]\n",
      "[ 8 2 5 | 1 6 4 | 7 9 3 ]\n",
      "[-----------------------]\n",
      "[ 2 7 1 | 6 4 5 | 3 8 9 ]\n",
      "[ 9 3 8 | 7 1 2 | 5 4 6 ]\n",
      "[ 5 4 6 | 8 3 9 | 1 7 2 ]\n",
      "[-----------------------]\n",
      "[ 1 8 4 | 2 9 3 | 6 5 7 ]\n",
      "[ 6 9 2 | 5 7 1 | 4 3 8 ]\n",
      "[ 7 5 3 | 4 8 6 | 9 2 1 ]\n",
      "[-----------------------]\n"
     ]
    }
   ],
   "source": [
    "using JuMP, GLPK\n",
    "function example_sudoku()\n",
    "    \n",
    "    # input the initial puzzle board (0s mean blanks)\n",
    "    initial_grid = [\n",
    "                    3 1 0 0 5 8 0 0 4;\n",
    "                    0 0 9 3 2 0 0 0 0;\n",
    "                    0 2 5 1 0 4 0 9 0;\n",
    "                    0 0 0 0 0 0 3 8 9;\n",
    "                    0 0 8 0 0 0 5 0 0;\n",
    "                    5 4 6 0 0 0 0 0 0;\n",
    "                    0 8 0 2 0 3 6 5 0;\n",
    "                    0 0 0 0 7 1 4 0 0;\n",
    "                    7 0 0 4 8 0 0 2 1\n",
    "                    ]\n",
    "\n",
    "    # use GLPK Optimizer\n",
    "    model = Model(GLPK.Optimizer)\n",
    "    \n",
    "    # Set up the variables: each one can only take on binary values, so we add \"Bin\" to the end as a constraint\n",
    "    @variable(model, x[1:9, 1:9, 1:9], Bin)\n",
    "\n",
    "    # Add the constraints\n",
    "    @constraints(model, begin\n",
    "                     # Constraint 1 - Only one value appears in each cell\n",
    "                     cell[i in 1:9, j in 1:9], sum(x[i, j, :]) == 1\n",
    "                     # Constraint 2 - Each value appears in each row once only\n",
    "                     row[i in 1:9, k in 1:9], sum(x[i, :, k]) == 1\n",
    "                     # Constraint 3 - Each value appears in each column once only\n",
    "                     col[j in 1:9, k in 1:9], sum(x[:, j, k]) == 1\n",
    "                     # Constraint 4 - Each value appears in each 3x3 subgrid once only\n",
    "                     subgrid[i=1:3:7, j=1:3:7, val=1:9], sum(x[i:i + 2, j:j + 2, val]) == 1\n",
    "                 end)\n",
    "\n",
    "    # Add additional constraints that reflect the starting point of the puzzle board\n",
    "    # (i.e. don't attempt to update the numbers that were given as part of the puzzle)\n",
    "    for row in 1:9, col in 1:9\n",
    "        if initial_grid[row, col] != 0\n",
    "            @constraint(model, x[row, col, initial_grid[row, col]] == 1)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # Solve it\n",
    "    JuMP.optimize!(model)\n",
    "\n",
    "    term_status = JuMP.termination_status(model)\n",
    "    primal_status = JuMP.primal_status(model)\n",
    "    is_optimal = term_status == MOI.OPTIMAL\n",
    "\n",
    "    # Check solution\n",
    "    if is_optimal\n",
    "        mip_solution = JuMP.value.(x)\n",
    "        sol = zeros(Int, 9, 9)\n",
    "        for row in 1:9, col in 1:9, val in 1:9\n",
    "            if mip_solution[row, col, val] >= 0.9\n",
    "                sol[row, col] = val\n",
    "            end\n",
    "        end\n",
    "        return sol\n",
    "    else\n",
    "        error(\"The solver did not find an optimal solution.\")\n",
    "    end\n",
    "end\n",
    "\n",
    "function print_sudoku_solution(solution)\n",
    "    println(\"Solution:\")\n",
    "    println(\"[-----------------------]\")\n",
    "    for row in 1:9\n",
    "        print(\"[ \")\n",
    "        for col in 1:9\n",
    "            print(solution[row, col], \" \")\n",
    "            if col % 3 == 0 && col < 9\n",
    "                print(\"| \")\n",
    "            end\n",
    "        end\n",
    "        println(\"]\")\n",
    "        if row % 3 == 0\n",
    "            println(\"[-----------------------]\")\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "sol = example_sudoku()\n",
    "print_sudoku_solution(sol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 3. Solving a salary cap problem\n",
    "NBA general managers want to build a championship team. What is their objective function? To win a championship. Well, that's difficult to exactly write down, but we can look at other more easily measurable outputs (like points scored, points allowed, etc.)\n",
    "    \n",
    "Suppose we want to find the team that will have the best statistics, but at the cheapest price.\n",
    "\n",
    "### Data\n",
    "I obtained the data using [this R script](https://github.com/tyleransom/DScourseS20/blob/master/WebData/getNBAplayerStats.R), which makes use of the `nbastatR` package. The data is in CSV format, which we will directly read into Julia using the `HTTP` and `JuliaDB` packages.\n",
    "\n",
    "### Objective function\n",
    "It's not clear what objective function we should use, but let's start with a simple one: maximize points scored.\n",
    "\n",
    "### Constraints\n",
    "We have at least two constraints: our team can only have 15 players on it, and the total team salary must be below the luxury tax threshold (\\\\$132.6m). We will talk about other important constraints after trying things out with this most basic constraint.\n",
    "\n",
    "### Variables\n",
    "In this case, the variables are the players that we pick. \n",
    "\n",
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "team: [\"Trae Young\", \"Jayson Tatum\", \"Jaylen Brown\", \"Zach LaVine\", \"Collin Sexton\", \"Domantas Sabonis\", \"Kendrick Nunn\", \"Giannis Antetokounmpo\", \"Brandon Ingram\", \"Shai Gilgeous-Alexander\", \"Buddy Hield\", \"Pascal Siakam\", \"Donovan Mitchell\", \"Luka Doncic\", \"Bradley Beal\"]\n",
      "total points scored per game: 354.3\n",
      "payroll: 132.53548\n"
     ]
    }
   ],
   "source": [
    "using HTTP, JuliaDB, JuMP, GLPK\n",
    "\n",
    "# first function: read in the player data from the class GitHub repository\n",
    "function read_in_data(url)\n",
    "    newtable  = csvread(IOBuffer(HTTP.get(url).body), skiplines_begin=0, header_exists=true)\n",
    "    players   = newtable[1][2]\n",
    "    salaries  = newtable[1][4]./1000000\n",
    "    ppg       = newtable[1][11]\n",
    "    return players,salaries,ppg\n",
    "end\n",
    "\n",
    "function SolveModel(players,salary,points)\n",
    "    N = length(salary) \n",
    "    \n",
    "    m = Model(GLPK.Optimizer)\n",
    "\n",
    "    # define the variables: they are 0 if the player did not make the team, 1 if the player did make the team\n",
    "    @variable(m, picked[1:N], Bin)\n",
    "\n",
    "    # categories: \n",
    "    @objective(m, Max, sum( points[i] * picked[i] for i in 1:N)) \n",
    "\n",
    "    @constraints m begin\n",
    "        # Constraint 1 - payroll <= 132.6m\n",
    "        sum(salary[i] * picked[i] for i in 1:N) <= 132.6\n",
    "        # Constraint 2 - must have exactly 15 players on roster\n",
    "        sum(picked[i] for i in 1:N) == 15\n",
    "    end\n",
    "\n",
    "    # Solve it\n",
    "    JuMP.optimize!(m);\n",
    "    pck     = convert(BitArray,JuMP.value.(picked))\n",
    "    lineup  = players[pck]\n",
    "    points  = JuMP.objective_value(m)\n",
    "    payroll = sum(salary[pck])\n",
    "    return lineup,points,payroll\n",
    "end\n",
    "\n",
    "# call first function (to import data)\n",
    "players,salaries,pts = read_in_data(\"https://raw.githubusercontent.com/tyleransom/DScourseS20/master/WebData/playerSalaryStats.csv\")\n",
    "\n",
    "# pass data into second function to get optimal lineup\n",
    "lineup,total_points,payroll = SolveModel(players,salaries,pts)\n",
    "println(\"team: \",lineup)\n",
    "println(\"total points scored per game: \",total_points)\n",
    "println(\"payroll: \",payroll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of our optimization tells us that with the team listed above, we should expect them to score more than 354 points per game! Unfortunately, that answer makes no sense. What went wrong?\n",
    "\n",
    "Two major things that went wrong:\n",
    "\n",
    "1. We didn't account for the fact that there are only 240 minutes in an NBA game (48 minutes times 5 players on the floor)\n",
    "2. We didn't account for the fact that teams can typically attempt no more than 80 field goals in an NBA game\n",
    "\n",
    "Let's adjust our code so that we account for these important constraints and see if we get anything more reasonable. We will need to add minutes and field goal attampts into our data import function, and we will need to add a constraint on total minutes and total field goal attempts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "team: [\"Damian Jones\", \"Javonte Green\", \"JaVale McGee\", \"Dwight Howard\", \"Goga Bitadze\", \"Jaxson Hayes\", \"Nerlens Noel\", \"Patrick Patterson\", \"Yogi Ferrell\", \"Chris Boucher\", \"Tony Bradley\", \"Mason Plumlee\", \"Thon Maker\", \"Christian Wood\", \"James Harden\"]\n",
      "total points scored per game: 121.0\n",
      "payroll: 84.22254099999999\n",
      "total shots per game: 79.89999999999999\n",
      "total minutes per game: 239.90000000000003\n"
     ]
    }
   ],
   "source": [
    "# first function: read in the player data from the class GitHub repository\n",
    "function read_in_data(url)\n",
    "    newtable = csvread(IOBuffer(HTTP.get(url).body), skiplines_begin=0, header_exists=true)\n",
    "    players  = newtable[1][2]\n",
    "    salaries = newtable[1][4]./1000000\n",
    "    mpg      = newtable[1][5]\n",
    "    fgaG5    = 1.0.*((newtable[1][9]).>5)\n",
    "    fga      = newtable[1][9]\n",
    "    ppg      = newtable[1][11]\n",
    "    return players,salaries,mpg,fgaG5,fga,ppg\n",
    "end\n",
    "\n",
    "function SolveModel(players,salary,minutes,field_goals_over5,field_goals,points)\n",
    "    N = length(salary) \n",
    "    \n",
    "    m = Model(GLPK.Optimizer)\n",
    "\n",
    "    # define the variables: they are 0 if the player did not make the team, 1 if the player did make the team\n",
    "    @variable(m, picked[1:N], Bin)\n",
    "\n",
    "    # categories: \n",
    "    @objective(m, Max, sum( points[i] * picked[i] for i in 1:N)) \n",
    "\n",
    "    @constraints m begin\n",
    "        # Constraint 1 - payroll <= 132.6m\n",
    "        sum(salary[i] * picked[i] for i in 1:N) <= 132.6\n",
    "        # Constraint 2 - must have exactly 15 players on roster\n",
    "        sum(picked[i] for i in 1:N) == 15\n",
    "        # Constraint 3 - total minutes must not exceed 240\n",
    "        sum(minutes[i] * picked[i] for i in 1:N) <= 240\n",
    "        # Constraint 4 - total shot attempts must be lower than 80\n",
    "        sum(field_goals[i] * picked[i] for i in 1:N) <= 80\n",
    "    end\n",
    "\n",
    "    # Solve it\n",
    "    JuMP.optimize!(m);\n",
    "    pck      = convert(BitArray,JuMP.value.(picked))\n",
    "    lineup   = players[pck]\n",
    "    totmin   = sum(minutes[pck])\n",
    "    payroll  = sum(salary[pck])\n",
    "    totshots = sum(field_goals[pck])\n",
    "    points   = JuMP.objective_value(m)\n",
    "    return lineup,points,totmin,payroll,totshots\n",
    "end\n",
    "\n",
    "# call first function (to import data)\n",
    "players,salaries,minutes,over5fg,fga,pts = read_in_data(\"https://raw.githubusercontent.com/tyleransom/DScourseS20/master/WebData/playerSalaryStats.csv\")\n",
    "\n",
    "# pass data into second function to get optimal lineup\n",
    "lineup,total_points,total_minutes,payroll,totshots = SolveModel(players,salaries,minutes,over5fg,fga,pts)\n",
    "println(\"team: \",lineup)\n",
    "println(\"total points scored per game: \",total_points)\n",
    "println(\"payroll: \",payroll)\n",
    "println(\"total shots per game: \",totshots)\n",
    "println(\"total minutes per game: \",total_minutes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results gives us a much mroe reasonable number of 121 points, 80 field goal attempts, and a super-cheap payroll of \\\\$84m, which is \\\\$25m lower than the lowest in the NBA right now.\n",
    "\n",
    "---\n",
    "\n",
    "# 4. Estimating Linear Regression Coefficients\n",
    "We can also use JuMP to estimate linear regression coefficients. In this case, we must use the `Ipopt` (pronounced eye-PEE-opt) optimizer. Why? Because our objective function is nonlinear (we are minimizing the sum of the squared residuals) and the optimizers we have used above are only valid for linear objective functions.\n",
    "\n",
    "### Objective function\n",
    "The objective function for OLS is\n",
    "\n",
    "\\begin{equation}\n",
    "\\min_{\\beta} \\sum_{i} (y_i - \\beta_0 - \\beta_1 x_1 - \\beta_2 x_2 - \\cdots - \\beta_k x_k)^2\n",
    "\\end{equation}\n",
    "\n",
    "### Variables\n",
    "The variables in this case are the parameters we want to estimate---the $\\beta$'s.\n",
    "\n",
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******************************************************************************\n",
      "This program contains Ipopt, a library for large-scale nonlinear optimization.\n",
      " Ipopt is released as open source code under the Eclipse Public License (EPL).\n",
      "         For more information visit http://projects.coin-or.org/Ipopt\n",
      "******************************************************************************\n",
      "\n",
      "This is Ipopt version 3.12.10, running with linear solver mumps.\n",
      "NOTE: Other linear solvers might be more efficient (see Ipopt documentation).\n",
      "\n",
      "Number of nonzeros in equality constraint Jacobian...:        0\n",
      "Number of nonzeros in inequality constraint Jacobian.:        0\n",
      "Number of nonzeros in Lagrangian Hessian.............:       10\n",
      "\n",
      "Total number of variables............................:        4\n",
      "                     variables with only lower bounds:        0\n",
      "                variables with lower and upper bounds:        0\n",
      "                     variables with only upper bounds:        0\n",
      "Total number of equality constraints.................:        0\n",
      "Total number of inequality constraints...............:        0\n",
      "        inequality constraints with only lower bounds:        0\n",
      "   inequality constraints with lower and upper bounds:        0\n",
      "        inequality constraints with only upper bounds:        0\n",
      "\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "   0  5.5361028e+03 0.00e+00 1.00e+02  -1.0 0.00e+00    -  0.00e+00 0.00e+00   0\n",
      "   1  8.0341708e+00 0.00e+00 2.37e-14  -1.0 9.28e+00    -  1.00e+00 1.00e+00f  1\n",
      "\n",
      "Number of Iterations....: 1\n",
      "\n",
      "                                   (scaled)                 (unscaled)\n",
      "Objective...............:   2.9676334739952230e-02    8.0341707763946211e+00\n",
      "Dual infeasibility......:   2.3739303738078894e-14    6.4268590449501054e-12\n",
      "Constraint violation....:   0.0000000000000000e+00    0.0000000000000000e+00\n",
      "Complementarity.........:   0.0000000000000000e+00    0.0000000000000000e+00\n",
      "Overall NLP error.......:   2.3739303738078894e-14    6.4268590449501054e-12\n",
      "\n",
      "\n",
      "Number of objective function evaluations             = 2\n",
      "Number of objective gradient evaluations             = 2\n",
      "Number of equality constraint evaluations            = 0\n",
      "Number of inequality constraint evaluations          = 0\n",
      "Number of equality constraint Jacobian evaluations   = 0\n",
      "Number of inequality constraint Jacobian evaluations = 0\n",
      "Number of Lagrangian Hessian evaluations             = 1\n",
      "Total CPU secs in IPOPT (w/o function evaluations)   =      7.216\n",
      "Total CPU secs in NLP function evaluations           =      3.174\n",
      "\n",
      "EXIT: Optimal Solution Found.\n",
      "Objective value: 8.034170776394621\n",
      "beta hat = [9.27849, -0.0296502, -0.115783, 0.0247281]\n",
      "RMSE = 0.33878292199313836\n"
     ]
    }
   ],
   "source": [
    "using HTTP, JuliaDB, JuMP, Ipopt\n",
    "function import_auto(url)\n",
    "    newtable  = csvread(IOBuffer(HTTP.get(url).body), skiplines_begin=0, header_exists=true)\n",
    "    depvar    = log.(newtable[1][2]) # log price\n",
    "    indepvars = cat(ones(size(depvar)),newtable[1][3],newtable[1][5],newtable[1][6]; dims=2) # constant, mpg, headroom, trunk\n",
    "    return depvar,indepvars\n",
    "end\n",
    "\n",
    "Y,X = import_auto(\"https://tyleransom.github.io/teaching/MetricsLabs/auto.csv\")\n",
    "\n",
    "\n",
    "function jumpOLS(Y,X,startval=zeros(size(X,2),1))\n",
    "    OLS = Model(Ipopt.Optimizer)\n",
    "    \n",
    "    # Declare the variables you are optimizing over\n",
    "    @variable(OLS, b[i=1:size(X,2)], start = startval[i])\n",
    "    \n",
    "    # Write your objective function\n",
    "    @NLobjective(OLS, Min, sum( (Y[i]-sum( X[i,k]*b[k] for k in 1:size(X,2) ))^2 for i in 1:size(X,1) ) )\n",
    "    \n",
    "    # Solve the objective function\n",
    "    JuMP.optimize!(OLS)\n",
    "    \n",
    "    SSR = JuMP.objective_value(OLS)\n",
    "    b_value = JuMP.value.(b)\n",
    "    println(\"Objective value: \", SSR)\n",
    "    println(\"beta hat = \", b_value)\n",
    "    println(\"RMSE = \", sqrt(SSR/(size(X,1)-size(X,2))))\n",
    "end\n",
    "\n",
    "jumpOLS(Y,X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check our answer in R with the following code:\n",
    "```r\n",
    "df <- read.csv(\"https://tyleransom.github.io/teaching/MetricsLabs/auto.csv\") %>% as_tibble %>% \n",
    "      mutate(logprice = log(price)) %>% \n",
    "      drop_na(foreign)\n",
    "summary(lm(logprice ~ mpg + headroom + trunk, data=df))\n",
    "```\n",
    "\n",
    "which gives us\n",
    "\n",
    "```\n",
    "Call:\n",
    "lm(formula = log(price) ~ mpg + headroom + trunk, data = df)\n",
    "\n",
    "Residuals:\n",
    "    Min      1Q  Median      3Q     Max \n",
    "-0.6017 -0.2521 -0.1082  0.2104  1.0445 \n",
    "\n",
    "Coefficients:\n",
    "             Estimate Std. Error t value Pr(>|t|)    \n",
    "(Intercept)  9.278489   0.314134  29.537  < 2e-16 ***\n",
    "mpg         -0.029650   0.008434  -3.515 0.000775 ***\n",
    "headroom    -0.115783   0.062605  -1.849 0.068619 .  \n",
    "trunk        0.024728   0.013857   1.785 0.078667 .  \n",
    "---\n",
    "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
    "\n",
    "Residual standard error: 0.3388 on 70 degrees of freedom\n",
    "Multiple R-squared:  0.2842,\tAdjusted R-squared:  0.2535 \n",
    "F-statistic: 9.263 on 3 and 70 DF,  p-value: 3.082e-05\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
